{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Accessibility Data: ML & Predictive Models\n",
        "\n",
        "This notebook implements three modeling tasks using the **Project Sidewalk Seattle** dataset:\n",
        "\n",
        "1. **Barrier type classification** — Classify types of accessibility barriers (surface problem, obstacle, curb ramp issue, etc.).\n",
        "2. **High-risk accessibility hotspots** — Identify hotspots using spatial clustering and risk scoring.\n",
        "3. **Future problem prediction** — Predict where new accessibility problems are likely to occur."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup and data load"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, r2_score, mean_absolute_error, mean_squared_error\n",
        "from sklearn.cluster import DBSCAN\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "pd.set_option('display.max_columns', 20)\n",
        "sns.set_style('whitegrid')\n",
        "%matplotlib inline\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('everydayLife_cleaned_dataset.csv')\n",
        "\n",
        "# Simplify column names\n",
        "df = df.rename(columns={\n",
        "    'geometry/coordinates/0': 'lon',\n",
        "    'geometry/coordinates/1': 'lat',\n",
        "    'properties/label_type': 'label_type',\n",
        "    'properties/neighborhood': 'neighborhood',\n",
        "    'properties/severity': 'severity',\n",
        "    'properties/is_temporary': 'is_temporary'\n",
        "})\n",
        "\n",
        "print('Shape:', df.shape)\n",
        "print('\\nLabel type distribution:')\n",
        "print(df['label_type'].value_counts())\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Task 1: Classify types of accessibility barriers\n",
        "\n",
        "**Goal:** Given a sidewalk observation's *location* (lon, lat), *neighborhood*, *severity rating*, and *temporary flag*, predict the **type of accessibility barrier** (CurbRamp, NoCurbRamp, NoSidewalk, SurfaceProblem, Obstacle, Occlusion, Other).\n",
        "\n",
        "**Why this matters:** Automating barrier classification can help city planners triage crowdsourced reports faster, fill in missing labels, and understand the relationship between *where* a barrier is and *what kind* of barrier it is.\n",
        "\n",
        "**Approach:**\n",
        "1. Exploratory analysis of class distribution, severity patterns, and spatial spread.\n",
        "2. Train a **Random Forest** (decision-tree ensemble) classifier.\n",
        "3. Evaluate with confusion matrix, per-class F1 scores, feature importance, and cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- EDA: Barrier type distribution and severity patterns ---\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "# (a) Class distribution\n",
        "order = df['label_type'].value_counts().index.tolist()\n",
        "palette = sns.color_palette('Set2', n_colors=len(order))\n",
        "ax = axes[0]\n",
        "sns.countplot(data=df, y='label_type', order=order, hue='label_type', palette=palette, legend=False, ax=ax)\n",
        "for i, v in enumerate(df['label_type'].value_counts()[order]):\n",
        "    ax.text(v + 200, i, f'{v:,}  ({v/len(df)*100:.1f}%)', va='center', fontsize=9)\n",
        "ax.set_title('Distribution of barrier types', fontsize=13, fontweight='bold')\n",
        "ax.set_xlabel('Count')\n",
        "ax.set_ylabel('')\n",
        "\n",
        "# (b) Severity by barrier type (violin)\n",
        "ax = axes[1]\n",
        "sns.violinplot(data=df, y='label_type', x='severity', order=order, hue='label_type',\n",
        "               palette=palette, legend=False, inner='quartile', ax=ax)\n",
        "ax.set_title('Severity distribution by barrier type', fontsize=13, fontweight='bold')\n",
        "ax.set_xlabel('Severity (1=low, 5=high)')\n",
        "ax.set_ylabel('')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Key stats\n",
        "print('Class counts and mean severity:')\n",
        "print(df.groupby('label_type').agg(count=('label_type','size'), mean_sev=('severity','mean'),\n",
        "      pct_temporary=('is_temporary','mean')).sort_values('count', ascending=False).round(3).to_string())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Interactive map: barrier types on real-world basemap (Google Maps style) ---\n",
        "\n",
        "import folium\n",
        "\n",
        "# Center on Seattle\n",
        "center_lat, center_lon = df['lat'].mean(), df['lon'].mean()\n",
        "\n",
        "# Basemap: use Google Maps tiles (roadmap). For strict Google ToS use an API key; this URL often works for demos.\n",
        "# Alternative: tiles='OpenStreetMap' for free OSM basemap.\n",
        "m_task1 = folium.Map(\n",
        "    location=[center_lat, center_lon],\n",
        "    zoom_start=11,\n",
        "    tiles=None,\n",
        "    control_scale=True\n",
        ")\n",
        "\n",
        "# Google Maps-style roadmap (no API key in URL; may have usage limits)\n",
        "folium.TileLayer(\n",
        "    tiles='https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}',\n",
        "    attr='Google',\n",
        "    name='Google Maps',\n",
        "    overlay=False,\n",
        "    control=True\n",
        ").add_to(m_task1)\n",
        "\n",
        "# OpenStreetMap as fallback / alternative\n",
        "folium.TileLayer('OpenStreetMap', name='OpenStreetMap', overlay=False, control=True).add_to(m_task1)\n",
        "\n",
        "# Barrier type colors (hex) matching the EDA palette\n",
        "order_types = df['label_type'].value_counts().index.tolist()\n",
        "palette_hex = ['#66c2a5', '#fc8d62', '#8da0cb', '#e78ac3', '#a6d854', '#ffd92f', '#e5c494']\n",
        "color_hex = dict(zip(order_types, palette_hex[:len(order_types)]))\n",
        "\n",
        "# Add one layer per barrier type (sampled for performance)\n",
        "max_per_type = 1200\n",
        "for label in order_types:\n",
        "    layer = folium.FeatureGroup(name=f'{label}')\n",
        "    sub = df[df['label_type'] == label]\n",
        "    if len(sub) > max_per_type:\n",
        "        sub = sub.sample(n=max_per_type, random_state=42)\n",
        "    for _, row in sub.iterrows():\n",
        "        folium.CircleMarker(\n",
        "            location=[row['lat'], row['lon']],\n",
        "            radius=3,\n",
        "            color=color_hex.get(label, '#333'),\n",
        "            fill=True,\n",
        "            fill_opacity=0.6,\n",
        "            weight=0,\n",
        "            popup=f\"<b>{label}</b><br>Severity: {row['severity']}<br>Temp: {row['is_temporary']}\"\n",
        "        ).add_to(layer)\n",
        "    layer.add_to(m_task1)\n",
        "\n",
        "folium.LayerControl(collapsed=False).add_to(m_task1)\n",
        "print('Barrier types overlaid on basemap. Toggle layers and basemap (Google / OSM) in the top-right.')\n",
        "m_task1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spatial distribution of barrier types is shown in the interactive Google Maps map in the next cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Features and target\n",
        "feature_cols = ['lon', 'lat', 'neighborhood', 'severity', 'is_temporary']\n",
        "target_col = 'label_type'\n",
        "\n",
        "X = df[['lon', 'lat', 'severity']].copy()\n",
        "X['is_temporary'] = df['is_temporary'].astype(int)\n",
        "\n",
        "# Encode neighborhood\n",
        "le_neighborhood = LabelEncoder()\n",
        "X['neighborhood_enc'] = le_neighborhood.fit_transform(df['neighborhood'].astype(str))\n",
        "\n",
        "# Ensure all columns are float for sklearn compatibility\n",
        "X = X.astype(float)\n",
        "\n",
        "y = df[target_col]\n",
        "\n",
        "# Drop rows with missing severity for modeling\n",
        "mask = X['severity'].notna()\n",
        "X_clean = X[mask].copy()\n",
        "y_clean = y[mask]\n",
        "X_clean = X_clean.fillna(X_clean.median(numeric_only=True))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_clean, y_clean, test_size=0.25, random_state=42, stratify=y_clean\n",
        ")\n",
        "\n",
        "target_names = sorted(y_clean.unique())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_s = scaler.fit_transform(X_train)\n",
        "X_test_s = scaler.transform(X_test)\n",
        "\n",
        "print('Train size:', len(X_train), '| Test size:', len(X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Random Forest Classifier ──\n",
        "clf = RandomForestClassifier(n_estimators=300, max_depth=25, min_samples_leaf=2,\n",
        "                             class_weight='balanced', random_state=42, n_jobs=-1)\n",
        "clf.fit(X_train_s, y_train)\n",
        "y_pred_rf = clf.predict(X_test_s)\n",
        "\n",
        "rf_acc = accuracy_score(y_test, y_pred_rf)\n",
        "rf_f1  = f1_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
        "rf_f1_per = f1_score(y_test, y_pred_rf, average=None, zero_division=0)\n",
        "\n",
        "print('=' * 60)\n",
        "print('  RANDOM FOREST — BARRIER TYPE CLASSIFICATION')\n",
        "print('=' * 60)\n",
        "print(classification_report(y_test, y_pred_rf, target_names=target_names, zero_division=0))\n",
        "print(f'Accuracy: {rf_acc:.4f}')\n",
        "print(f'F1 (weighted): {rf_f1:.4f}')\n",
        "\n",
        "# Per-class results table\n",
        "results = pd.DataFrame({\n",
        "    'Class': target_names,\n",
        "    'F1 Score': rf_f1_per\n",
        "}).sort_values('F1 Score', ascending=False)\n",
        "results.loc[len(results)] = ['WEIGHTED AVG', rf_f1]\n",
        "print('\\n' + results.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Confusion matrix heatmap (row-normalized) ──\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(9, 7))\n",
        "cm = confusion_matrix(y_test, y_pred_rf, labels=target_names)\n",
        "cm_norm = cm.astype(float) / cm.sum(axis=1, keepdims=True)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_norm, display_labels=target_names)\n",
        "disp.plot(ax=ax, cmap='Blues', values_format='.2f', colorbar=True)\n",
        "ax.set_title('Random Forest — Confusion Matrix (row-normalized recall)', fontsize=13, fontweight='bold')\n",
        "ax.set_xlabel('Predicted label')\n",
        "ax.set_ylabel('True label')\n",
        "ax.set_xticklabels(target_names, rotation=45, ha='right', fontsize=9)\n",
        "ax.set_yticklabels(target_names, fontsize=9)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Per-class F1 Score bar chart ──\n",
        "\n",
        "f1_df = pd.DataFrame({\n",
        "    'Class': target_names,\n",
        "    'F1 Score': rf_f1_per\n",
        "}).sort_values('F1 Score', ascending=True)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "colors = ['#ef5350' if v < 0.5 else '#FF9800' if v < 0.7 else '#4CAF50' for v in f1_df['F1 Score']]\n",
        "bars = ax.barh(f1_df['Class'], f1_df['F1 Score'], color=colors, edgecolor='white')\n",
        "ax.axvline(rf_f1, color='#2196F3', ls='--', lw=1.5, label=f'Weighted avg ({rf_f1:.3f})')\n",
        "for i, (val, name) in enumerate(zip(f1_df['F1 Score'], f1_df['Class'])):\n",
        "    ax.text(val + 0.01, i, f'{val:.3f}', va='center', fontsize=10)\n",
        "ax.set_xlim(0, 1.1)\n",
        "ax.set_title('Random Forest — Per-class F1 Score', fontsize=13, fontweight='bold')\n",
        "ax.set_xlabel('F1 Score')\n",
        "ax.legend(fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ── Feature importance (Random Forest) ──\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 4))\n",
        "imp = pd.DataFrame({\n",
        "    'Feature': X_clean.columns,\n",
        "    'Importance': clf.feature_importances_\n",
        "}).sort_values('Importance', ascending=True)\n",
        "\n",
        "colors = sns.color_palette('viridis', n_colors=len(imp))\n",
        "ax.barh(imp['Feature'], imp['Importance'], color=colors)\n",
        "for i, (val, name) in enumerate(zip(imp['Importance'], imp['Feature'])):\n",
        "    ax.text(val + 0.005, i, f'{val:.3f}', va='center', fontsize=9)\n",
        "ax.set_title('Random Forest — Feature importance for barrier classification',\n",
        "             fontsize=12, fontweight='bold')\n",
        "ax.set_xlabel('Importance (Gini)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 1 — Key findings\n",
        "\n",
        "| Insight | Detail |\n",
        "|---|---|\n",
        "| **Class imbalance** | CurbRamp and NoSidewalk dominate; Occlusion and Other are very rare (<1%). This skew makes minority classes harder to classify. |\n",
        "| **Severity by type** | SurfaceProblem and Obstacle tend toward higher severity; CurbRamp clusters around low severity. Severity is a strong discriminating feature. |\n",
        "| **Spatial clustering** | Barrier types cluster by location — e.g. NoSidewalk in peripheral areas, CurbRamp in denser grids. Lon/lat and neighborhood drive predictions. |\n",
        "| **Feature importance** | The Random Forest relies most on location (lon, lat), then severity, then neighborhood. These features are sufficient to distinguish most barrier types. |\n",
        "| **Confusion matrix** | Obstacle and SurfaceProblem are most often confused with each other (similar locations and severity). CurbRamp and NoSidewalk are usually predicted correctly. |\n",
        "| **Balanced class weights** | Using `class_weight='balanced'` in the Random Forest upweights rare classes, improving recall for Obstacle, Occlusion, and Other. |\n",
        "| **Takeaway** | We can classify barrier type from location, severity, and neighborhood with strong weighted F1 using a decision-tree ensemble (Random Forest). The model supports triaging crowdsourced reports and understanding where different barrier types concentrate. |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Task 2: High-Risk Accessibility Hotspots (Spatial Clustering)\n",
        "\n",
        "**Goal:** Identify geographic clusters of accessibility barriers and rank them by risk score to prioritize remediation efforts.\n",
        "\n",
        "**Why this matters:** City planners have limited budgets for accessibility improvements. By identifying *hotspots* — areas with many high-severity barriers concentrated together — resources can be allocated where they'll have the greatest impact.\n",
        "\n",
        "**Approach:**\n",
        "1. Use **DBSCAN** to find clusters of nearby barriers.\n",
        "2. Calculate a **risk score** for each cluster: `count × mean severity`.\n",
        "3. Analyze which **neighborhoods** contain the most high-risk hotspots.\n",
        "4. Visualize hotspots on an interactive map."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Use DBSCAN for spatial clustering\n",
        "# Convert lat/lon to approximate meters for Seattle\n",
        "coords = df[['lon', 'lat']].values\n",
        "coords_scaled = coords.copy()\n",
        "coords_scaled[:, 0] *= 85000  # lon to meters at Seattle latitude\n",
        "coords_scaled[:, 1] *= 111000  # lat to meters\n",
        "\n",
        "print(\"Running DBSCAN clustering...\")\n",
        "dbscan = DBSCAN(eps=100, min_samples=5)  # 100m radius, minimum 5 points\n",
        "df['cluster'] = dbscan.fit_predict(coords_scaled)\n",
        "\n",
        "n_clusters = len(set(df['cluster'])) - (1 if -1 in df['cluster'] else 0)\n",
        "n_noise = list(df['cluster']).count(-1)\n",
        "\n",
        "print(f\"\\n✓ Clustering complete!\")\n",
        "print(f\"Number of clusters: {n_clusters}\")\n",
        "print(f\"Noise points: {n_noise:,} ({n_noise/len(df)*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate risk score per cluster: count × mean severity\n",
        "cluster_stats = df[df['cluster'] != -1].groupby('cluster').agg({\n",
        "    'severity': ['mean', 'std', 'count'],\n",
        "    'lon': 'mean',\n",
        "    'lat': 'mean'\n",
        "}).reset_index()\n",
        "\n",
        "cluster_stats.columns = ['cluster', 'mean_severity', 'std_severity', 'count', 'lon', 'lat']\n",
        "cluster_stats['risk_score'] = cluster_stats['count'] * cluster_stats['mean_severity']\n",
        "cluster_stats = cluster_stats.sort_values('risk_score', ascending=False)\n",
        "\n",
        "print(\"Top 10 High-Risk Clusters:\")\n",
        "print(cluster_stats.head(10)[['cluster', 'count', 'mean_severity', 'risk_score']])\n",
        "\n",
        "# Visualize clusters\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Left: All clusters colored by cluster ID\n",
        "clustered = df[df['cluster'] != -1]\n",
        "axes[0].scatter(clustered['lon'], clustered['lat'], c=clustered['cluster'], \n",
        "               s=2, cmap='tab20', alpha=0.5)\n",
        "axes[0].set_title('Spatial Clusters (DBSCAN)', fontsize=14, fontweight='bold')\n",
        "axes[0].set_xlabel('Longitude')\n",
        "axes[0].set_ylabel('Latitude')\n",
        "\n",
        "# Right: Clusters colored by risk score\n",
        "scatter = axes[1].scatter(cluster_stats['lon'], cluster_stats['lat'], \n",
        "                         c=cluster_stats['risk_score'], s=cluster_stats['count']*2,\n",
        "                         cmap='YlOrRd', alpha=0.7, edgecolors='black', linewidth=0.5)\n",
        "plt.colorbar(scatter, ax=axes[1], label='Risk Score')\n",
        "axes[1].set_title('High-Risk Hotspots', fontsize=14, fontweight='bold')\n",
        "axes[1].set_xlabel('Longitude')\n",
        "axes[1].set_ylabel('Latitude')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Neighborhood-level hotspot analysis ---\n",
        "\n",
        "# Assign each cluster to its dominant neighborhood\n",
        "cluster_neighborhoods = df[df['cluster'] != -1].groupby('cluster')['neighborhood'].agg(\n",
        "    lambda x: x.mode()[0] if len(x.mode()) > 0 else 'Unknown'\n",
        ").reset_index()\n",
        "cluster_neighborhoods.columns = ['cluster', 'neighborhood']\n",
        "\n",
        "# Merge with cluster stats\n",
        "cluster_stats_full = cluster_stats.merge(cluster_neighborhoods, on='cluster', how='left')\n",
        "\n",
        "# Top 20 high-risk clusters with neighborhoods\n",
        "print(\"Top 20 High-Risk Hotspots by Neighborhood:\")\n",
        "print(cluster_stats_full.head(20)[['cluster', 'neighborhood', 'count', 'mean_severity', 'risk_score']].to_string(index=False))\n",
        "\n",
        "# Aggregate by neighborhood\n",
        "neighborhood_risk = cluster_stats_full.groupby('neighborhood').agg({\n",
        "    'cluster': 'count',\n",
        "    'count': 'sum',\n",
        "    'risk_score': 'sum',\n",
        "    'mean_severity': 'mean'\n",
        "}).reset_index()\n",
        "neighborhood_risk.columns = ['neighborhood', 'n_clusters', 'total_issues', 'total_risk', 'avg_severity']\n",
        "neighborhood_risk = neighborhood_risk.sort_values('total_risk', ascending=False)\n",
        "\n",
        "# Visualization: Top 15 neighborhoods by total risk\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# (a) Bar chart - neighborhoods by risk\n",
        "top_hoods = neighborhood_risk.head(15).sort_values('total_risk', ascending=True)\n",
        "colors = plt.cm.YlOrRd(np.linspace(0.3, 0.9, len(top_hoods)))\n",
        "axes[0].barh(top_hoods['neighborhood'], top_hoods['total_risk'], color=colors, edgecolor='black', linewidth=0.5)\n",
        "axes[0].set_xlabel('Total Risk Score', fontsize=12, fontweight='bold')\n",
        "axes[0].set_title('Top 15 Neighborhoods by Total Risk Score', fontsize=13, fontweight='bold')\n",
        "\n",
        "# (b) Bubble chart - clusters vs severity\n",
        "scatter = axes[1].scatter(neighborhood_risk['n_clusters'], neighborhood_risk['avg_severity'],\n",
        "    s=neighborhood_risk['total_issues'] / 5, c=neighborhood_risk['total_risk'], cmap='YlOrRd', alpha=0.7, edgecolors='black')\n",
        "axes[1].set_xlabel('Number of Clusters', fontsize=12, fontweight='bold')\n",
        "axes[1].set_ylabel('Average Severity', fontsize=12, fontweight='bold')\n",
        "axes[1].set_title('Neighborhoods: Clusters vs Severity (size=issue count)', fontsize=13, fontweight='bold')\n",
        "plt.colorbar(scatter, ax=axes[1], label='Total Risk Score')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nNeighborhood Summary (top 10):\")\n",
        "print(neighborhood_risk.head(10).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Interactive map: High-risk hotspots on Google Maps ---\n",
        "\n",
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "from branca.colormap import LinearColormap\n",
        "\n",
        "# Center on Seattle\n",
        "center_lat, center_lon = df['lat'].mean(), df['lon'].mean()\n",
        "\n",
        "# Create map with Google Maps basemap\n",
        "m_task2 = folium.Map(location=[center_lat, center_lon], zoom_start=11, tiles=None)\n",
        "\n",
        "# Add basemaps\n",
        "folium.TileLayer(tiles='https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}',\n",
        "    attr='Google', name='Google Maps', overlay=False).add_to(m_task2)\n",
        "folium.TileLayer('OpenStreetMap', name='OpenStreetMap', overlay=False).add_to(m_task2)\n",
        "\n",
        "# Color scale based on risk score\n",
        "max_risk = cluster_stats_full['risk_score'].max()\n",
        "colormap = LinearColormap(['#fee5d9', '#fcae91', '#fb6a4a', '#de2d26', '#a50f15'],\n",
        "                          vmin=0, vmax=max_risk, caption='Risk Score')\n",
        "colormap.add_to(m_task2)\n",
        "\n",
        "# Add top 50 hotspots as circles\n",
        "for _, row in cluster_stats_full.head(50).iterrows():\n",
        "    radius = min(max(row['count'] * 0.5, 50), 500)\n",
        "    color = colormap(row['risk_score'])\n",
        "    folium.Circle(\n",
        "        location=[row['lat'], row['lon']], radius=radius,\n",
        "        color=color, fill=True, fill_color=color, fill_opacity=0.5, weight=2,\n",
        "        popup=f\"<b>Hotspot #{int(row['cluster'])}</b><br>Neighborhood: {row['neighborhood']}<br>\"\n",
        "              f\"Issues: {int(row['count'])}<br>Avg Severity: {row['mean_severity']:.2f}<br>\"\n",
        "              f\"Risk Score: {row['risk_score']:.0f}\"\n",
        "    ).add_to(m_task2)\n",
        "\n",
        "# Add heatmap layer\n",
        "heat_data = cluster_stats_full[['lat', 'lon', 'risk_score']].values.tolist()\n",
        "HeatMap(heat_data, radius=20, blur=15, name='Risk Heatmap').add_to(m_task2)\n",
        "\n",
        "folium.LayerControl(collapsed=False).add_to(m_task2)\n",
        "print('Interactive map: Top 50 high-risk hotspots (click circles for details)')\n",
        "m_task2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Task 2 — Key findings\n",
        "\n",
        "| Insight | Detail |\n",
        "|---|---|\n",
        "| **370 spatial clusters** | DBSCAN identified 370 distinct hotspots with only 0.4% noise points, indicating strong spatial clustering of accessibility barriers. |\n",
        "| **Risk score formula** | `count × mean severity` effectively ranks clusters — top clusters have both high volume and severity. |\n",
        "| **Dominant hotspots** | The top 2 clusters contain ~57,000 issues combined (70% of data), likely representing major arterial corridors. |\n",
        "| **Neighborhood concentration** | A handful of neighborhoods account for the majority of total risk — prioritize these for infrastructure investment. |\n",
        "| **Severity variability** | Some clusters have high severity but low count; others have high count but moderate severity. Both patterns require different interventions. |\n",
        "| **Actionable insight** | City planners should prioritize hotspots with *both* high count and high severity, as interventions there address the most barriers per dollar spent. |\n",
        "| **Takeaway** | DBSCAN + risk scoring provides a data-driven method to identify and rank accessibility hotspots, enabling targeted infrastructure improvements. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Task 3: Future Problem Prediction (PRIMARY MODEL)\n",
        "### This is our most accurate model - 95.3% R² score!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create spatial grid (0.005 degrees ≈ 500 meters)\n",
        "print(\"Creating spatial grid...\")\n",
        "grid_size = 0.005\n",
        "\n",
        "df['grid_lon'] = (df['lon'] // grid_size) * grid_size\n",
        "df['grid_lat'] = (df['lat'] // grid_size) * grid_size\n",
        "df['grid_id'] = df['grid_lon'].astype(str) + '_' + df['grid_lat'].astype(str)\n",
        "\n",
        "print(f\"✓ Created {df['grid_id'].nunique()} grid cells\")\n",
        "print(f\"Average issues per cell: {len(df) / df['grid_id'].nunique():.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aggregate features by grid cell\n",
        "grid_features = df.groupby('grid_id').agg({\n",
        "    'lon': 'mean',\n",
        "    'lat': 'mean',\n",
        "    'properties/attribute_id': 'count',\n",
        "    'severity': ['mean', 'max', 'std'],\n",
        "    'is_temporary': 'sum',\n",
        "    'label_type': lambda x: x.nunique(),\n",
        "}).reset_index()\n",
        "\n",
        "# Flatten column names\n",
        "grid_features.columns = ['grid_id', 'center_lon', 'center_lat', 'issue_count', \n",
        "                         'avg_severity', 'max_severity', 'std_severity', \n",
        "                         'temp_count', 'issue_type_diversity']\n",
        "\n",
        "grid_features['std_severity'] = grid_features['std_severity'].fillna(0)\n",
        "\n",
        "# Add issue type distribution\n",
        "issue_types = pd.get_dummies(df['label_type'], prefix='type')\n",
        "issue_types['grid_id'] = df['grid_id']\n",
        "type_counts = issue_types.groupby('grid_id').sum()\n",
        "grid_features = grid_features.merge(type_counts, on='grid_id', how='left').fillna(0)\n",
        "\n",
        "# Add neighborhood\n",
        "neighborhood_mode = df.groupby('grid_id')['neighborhood'].agg(\n",
        "    lambda x: x.mode()[0] if len(x.mode()) > 0 else 'Unknown'\n",
        ")\n",
        "grid_features = grid_features.merge(\n",
        "    neighborhood_mode.rename('neighborhood'), on='grid_id', how='left'\n",
        ")\n",
        "\n",
        "# Encode neighborhood\n",
        "le_grid = LabelEncoder()\n",
        "grid_features['neighborhood_encoded'] = le_grid.fit_transform(grid_features['neighborhood'])\n",
        "\n",
        "print(f\"✓ Grid features created: {grid_features.shape}\")\n",
        "print(f\"\\nFeature columns: {list(grid_features.columns)}\")\n",
        "print(f\"\\nSample grid data:\")\n",
        "print(grid_features.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare features for prediction\n",
        "feature_cols = ['center_lon', 'center_lat', 'avg_severity', 'max_severity', \n",
        "                'std_severity', 'temp_count', 'issue_type_diversity',\n",
        "                'type_CurbRamp', 'type_NoCurbRamp', 'type_NoSidewalk', \n",
        "                'type_Obstacle', 'type_Occlusion', 'type_Other', \n",
        "                'type_SurfaceProblem', 'neighborhood_encoded']\n",
        "\n",
        "X = grid_features[feature_cols]\n",
        "y = grid_features['issue_count']\n",
        "\n",
        "print(f\"Features: {len(feature_cols)}\")\n",
        "print(f\"Target (issue_count): min={y.min():.0f}, max={y.max():.0f}, mean={y.mean():.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model A: Regression (Predict Issue Count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train regression model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training regression model...\")\n",
        "reg_model = RandomForestRegressor(\n",
        "    n_estimators=100, \n",
        "    max_depth=10, \n",
        "    random_state=42, \n",
        "    n_jobs=-1\n",
        ")\n",
        "reg_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred = reg_model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"REGRESSION MODEL PERFORMANCE\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"R² Score:  {r2:.4f} ({r2*100:.1f}% variance explained)\")\n",
        "print(f\"RMSE:      {rmse:.2f} issues\")\n",
        "print(f\"MAE:       {mae:.2f} issues\")\n",
        "\n",
        "# Prediction accuracy within ranges\n",
        "within_5 = np.sum(np.abs(y_test - y_pred) <= 5) / len(y_test)\n",
        "within_10 = np.sum(np.abs(y_test - y_pred) <= 10) / len(y_test)\n",
        "within_20 = np.sum(np.abs(y_test - y_pred) <= 20) / len(y_test)\n",
        "\n",
        "print(f\"\\nPrediction Accuracy:\")\n",
        "print(f\"  Within ±5 issues:  {within_5:.2%}\")\n",
        "print(f\"  Within ±10 issues: {within_10:.2%}\")\n",
        "print(f\"  Within ±20 issues: {within_20:.2%}\")\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature importance\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': feature_cols,\n",
        "    'importance': reg_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(importance_df.head(10).to_string(index=False))\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10, 6))\n",
        "top_features = importance_df.head(10).sort_values('importance', ascending=True)\n",
        "plt.barh(top_features['feature'], top_features['importance'], color='coral')\n",
        "plt.xlabel('Importance Score', fontsize=12)\n",
        "plt.title('Top 10 Feature Importance - Future Problem Prediction', fontsize=14, fontweight='bold')\n",
        "plt.grid(axis='x', alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model B: Classification (Predict Risk Level)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create risk categories\n",
        "def categorize_risk(count):\n",
        "    if count < 30:\n",
        "        return 'Low'\n",
        "    elif count < 100:\n",
        "        return 'Medium'\n",
        "    else:\n",
        "        return 'High'\n",
        "\n",
        "grid_features['risk_level'] = grid_features['issue_count'].apply(categorize_risk)\n",
        "\n",
        "print(\"Risk Level Distribution:\")\n",
        "print(grid_features['risk_level'].value_counts())\n",
        "\n",
        "# Train classification model\n",
        "y_class = grid_features['risk_level']\n",
        "X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(\n",
        "    X, y_class, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\nTraining classification model...\")\n",
        "clf_model = RandomForestClassifier(\n",
        "    n_estimators=100, \n",
        "    max_depth=10, \n",
        "    random_state=42, \n",
        "    n_jobs=-1\n",
        ")\n",
        "clf_model.fit(X_train_c, y_train_c)\n",
        "\n",
        "# Predictions\n",
        "y_pred_c = clf_model.predict(X_test_c)\n",
        "accuracy = (y_pred_c == y_test_c).mean()\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"CLASSIFICATION MODEL PERFORMANCE\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
        "\n",
        "# F1 scores\n",
        "f1_weighted = f1_score(y_test_c, y_pred_c, average='weighted')\n",
        "f1_macro = f1_score(y_test_c, y_pred_c, average='macro')\n",
        "\n",
        "print(f\"\\nF1 Scores:\")\n",
        "print(f\"  Weighted F1: {f1_weighted:.4f}\")\n",
        "print(f\"  Macro F1:    {f1_macro:.4f}\")\n",
        "\n",
        "print(f\"\\nDetailed Report:\")\n",
        "print(classification_report(y_test_c, y_pred_c))\n",
        "print(f\"{'='*70}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_c, y_pred_c, labels=['High', 'Low', 'Medium'])\n",
        "cm_df = pd.DataFrame(cm, \n",
        "                     index=['Actual High', 'Actual Low', 'Actual Medium'],\n",
        "                     columns=['Pred High', 'Pred Low', 'Pred Medium'])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_df, annot=True, fmt='d', cmap='Blues', cbar_kws={'label': 'Count'})\n",
        "plt.title('Confusion Matrix - Risk Level Classification', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Comprehensive Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on all grid cells for visualization\n",
        "grid_features['predicted_issues'] = reg_model.predict(X)\n",
        "grid_features['predicted_risk'] = clf_model.predict(X)\n",
        "\n",
        "# Create comprehensive visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('Accessibility Prediction Model Results', fontsize=16, fontweight='bold', y=0.995)\n",
        "\n",
        "# 1. Actual vs Predicted (Regression)\n",
        "axes[0, 0].scatter(y_test, y_pred, alpha=0.6, s=60, color='steelblue', \n",
        "                  edgecolors='black', linewidth=0.5)\n",
        "max_val = max(y_test.max(), y_pred.max())\n",
        "axes[0, 0].plot([0, max_val], [0, max_val], 'r--', lw=2, label='Perfect Prediction')\n",
        "axes[0, 0].set_xlabel('Actual Issue Count', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_ylabel('Predicted Issue Count', fontsize=12, fontweight='bold')\n",
        "axes[0, 0].set_title(f'Actual vs Predicted (R² = {r2:.3f})', fontsize=13, fontweight='bold')\n",
        "axes[0, 0].legend(fontsize=10)\n",
        "axes[0, 0].grid(alpha=0.3)\n",
        "\n",
        "# 2. Feature Importance\n",
        "top_features = importance_df.head(10).sort_values('importance', ascending=True)\n",
        "colors = plt.cm.viridis(np.linspace(0.3, 0.9, len(top_features)))\n",
        "axes[0, 1].barh(top_features['feature'], top_features['importance'], \n",
        "                color=colors, edgecolor='black', linewidth=0.5)\n",
        "axes[0, 1].set_xlabel('Importance Score', fontsize=12, fontweight='bold')\n",
        "axes[0, 1].set_title('Top 10 Feature Importance', fontsize=13, fontweight='bold')\n",
        "axes[0, 1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# 3. Spatial Heatmap\n",
        "scatter = axes[1, 0].scatter(\n",
        "    grid_features['center_lon'], \n",
        "    grid_features['center_lat'], \n",
        "    c=grid_features['predicted_issues'], \n",
        "    cmap='YlOrRd', \n",
        "    s=100, \n",
        "    alpha=0.7, \n",
        "    edgecolors='black', \n",
        "    linewidth=0.5\n",
        ")\n",
        "axes[1, 0].set_xlabel('Longitude', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_ylabel('Latitude', fontsize=12, fontweight='bold')\n",
        "axes[1, 0].set_title('Predicted Risk Heatmap (Darker = Higher Risk)', \n",
        "                     fontsize=13, fontweight='bold')\n",
        "cbar = plt.colorbar(scatter, ax=axes[1, 0])\n",
        "cbar.set_label('Predicted Issues', fontsize=11, fontweight='bold')\n",
        "\n",
        "# 4. Distribution Comparison\n",
        "bins = np.linspace(0, max(grid_features['issue_count'].max(), \n",
        "                         grid_features['predicted_issues'].max()), 40)\n",
        "axes[1, 1].hist(grid_features['issue_count'], bins=bins, alpha=0.6, \n",
        "               label='Actual', color='dodgerblue', edgecolor='black', linewidth=0.8)\n",
        "axes[1, 1].hist(grid_features['predicted_issues'], bins=bins, alpha=0.6, \n",
        "               label='Predicted', color='orangered', edgecolor='black', linewidth=0.8)\n",
        "axes[1, 1].set_xlabel('Issue Count', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_ylabel('Frequency (# of Grid Cells)', fontsize=12, fontweight='bold')\n",
        "axes[1, 1].set_title('Distribution: Actual vs Predicted', fontsize=13, fontweight='bold')\n",
        "axes[1, 1].legend(fontsize=11)\n",
        "axes[1, 1].grid(axis='y', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Identify Top Future Risk Zones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate future risk score (predicted - observed)\n",
        "grid_features['future_risk_score'] = grid_features['predicted_issues'] - grid_features['issue_count']\n",
        "\n",
        "# Get top 50 highest future risk zones\n",
        "future_hotspots = grid_features.nlargest(50, 'future_risk_score')\n",
        "\n",
        "print(\"Top 20 Future Risk Zones:\")\n",
        "print(future_hotspots[['center_lon', 'center_lat', 'neighborhood', \n",
        "                        'issue_count', 'predicted_issues', 'future_risk_score']].head(20))\n",
        "\n",
        "# --- Map 1: Predicted issue count on Google Maps ---\n",
        "import folium\n",
        "from folium.plugins import HeatMap\n",
        "from IPython.display import display\n",
        "\n",
        "center_lat = grid_features['center_lat'].mean()\n",
        "center_lon = grid_features['center_lon'].mean()\n",
        "\n",
        "m1 = folium.Map(location=[center_lat, center_lon], zoom_start=11, tiles=None, control_scale=True)\n",
        "folium.TileLayer(tiles='https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}', attr='Google', name='Google Maps', overlay=False, control=True).add_to(m1)\n",
        "folium.TileLayer('OpenStreetMap', name='OpenStreetMap', overlay=False, control=True).add_to(m1)\n",
        "\n",
        "heat_data = grid_features[['center_lat', 'center_lon', 'predicted_issues']].values.tolist()\n",
        "HeatMap(heat_data, radius=15, blur=18, max_zoom=14, name='Predicted issue count').add_to(m1)\n",
        "folium.LayerControl(collapsed=False).add_to(m1)\n",
        "print('Map 1: Predicted barrier count per grid cell')\n",
        "display(m1)\n",
        "\n",
        "# --- Map 2: Future risk score + Top 50 zones on Google Maps ---\n",
        "m2 = folium.Map(location=[center_lat, center_lon], zoom_start=11, tiles=None, control_scale=True)\n",
        "folium.TileLayer(tiles='https://mt1.google.com/vt/lyrs=m&x={x}&y={y}&z={z}', attr='Google', name='Google Maps', overlay=False, control=True).add_to(m2)\n",
        "folium.TileLayer('OpenStreetMap', name='OpenStreetMap', overlay=False, control=True).add_to(m2)\n",
        "\n",
        "future_risk_data = grid_features[['center_lat', 'center_lon', 'future_risk_score']].copy()\n",
        "future_risk_data['future_risk_score'] = future_risk_data['future_risk_score'].clip(lower=0)\n",
        "heat_data2 = future_risk_data.values.tolist()\n",
        "HeatMap(heat_data2, radius=15, blur=18, max_zoom=14, name='Future risk score').add_to(m2)\n",
        "\n",
        "for _, row in future_hotspots.iterrows():\n",
        "    folium.Circle(\n",
        "        location=[row['center_lat'], row['center_lon']],\n",
        "        radius=200,\n",
        "        color='darkred', fill=True, fill_color='red', fill_opacity=0.2,\n",
        "        weight=2,\n",
        "        popup=f\"<b>{row['neighborhood']}</b><br>Observed: {int(row['issue_count'])}<br>Predicted: {row['predicted_issues']:.0f}<br>Future risk: {row['future_risk_score']:.1f}\"\n",
        "    ).add_to(m2)\n",
        "folium.LayerControl(collapsed=False).add_to(m2)\n",
        "print('Map 2: Where future accessibility problems are likely (top 50 zones in red circles)')\n",
        "display(m2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save trained models\n",
        "with open('accessibility_regression_model.pkl', 'wb') as f:\n",
        "    pickle.dump(reg_model, f)\n",
        "\n",
        "with open('accessibility_classification_model.pkl', 'wb') as f:\n",
        "    pickle.dump(clf_model, f)\n",
        "\n",
        "with open('label_encoder_grid.pkl', 'wb') as f:\n",
        "    pickle.dump(le_grid, f)\n",
        "\n",
        "print(\"✓ Models saved successfully!\")\n",
        "print(\"  • accessibility_regression_model.pkl\")\n",
        "print(\"  • accessibility_classification_model.pkl\")\n",
        "print(\"  • label_encoder_grid.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary\n",
        "\n",
        "- **Task 1** — Barrier type is predicted from location, neighborhood, severity, and temporary flag; feature importance highlights which factors drive barrier type.\n",
        "- **Task 2** — DBSCAN finds spatial clusters; risk score (count × mean severity) ranks clusters to identify **high-risk accessibility hotspots**.\n",
        "- **Task 3** — Grid-based count and high-risk models, plus a future-risk score (predicted − observed), identify **where future accessibility problems are likely** for prioritization and planning."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.14.2)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
